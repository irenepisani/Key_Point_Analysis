{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KPA_KeyPointMatching28/09.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZPit-0frpOlu",
        "5ua15ByQpXf7",
        "yGLkyccHpoxI",
        "UIXT3uQvqo4X",
        "wZ8vjt0R4tal",
        "_mb6JpyUq4Op",
        "yswPXNh15Uul",
        "rWvbLzMepoVH"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eb539cd48e724460adc74fa8609cc7d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4f7a4253987449ba9072925ef4dae66",
              "IPY_MODEL_148a1ad99fb74b92827deffce600b2e4",
              "IPY_MODEL_8cff21ac2f7a486186d552443fd6edf1"
            ],
            "layout": "IPY_MODEL_ba67ddb9dd1a4a4b94371fbe26e033bd"
          }
        },
        "d4f7a4253987449ba9072925ef4dae66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fbc91e74b934b7686aa41013afb96f6",
            "placeholder": "​",
            "style": "IPY_MODEL_7095fd34ae4841988128e9ebb95873d6",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "148a1ad99fb74b92827deffce600b2e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3af64b82f5647528368efdf2112f089",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61315eabf44c4c8eb07c850f2d882266",
            "value": 52
          }
        },
        "8cff21ac2f7a486186d552443fd6edf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_963d18c57f334739ba06e5f3ef10e961",
            "placeholder": "​",
            "style": "IPY_MODEL_90dabb31e217413a9adcdaf5afefd166",
            "value": " 52.0/52.0 [00:00&lt;00:00, 856B/s]"
          }
        },
        "ba67ddb9dd1a4a4b94371fbe26e033bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fbc91e74b934b7686aa41013afb96f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7095fd34ae4841988128e9ebb95873d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3af64b82f5647528368efdf2112f089": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61315eabf44c4c8eb07c850f2d882266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "963d18c57f334739ba06e5f3ef10e961": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90dabb31e217413a9adcdaf5afefd166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44844bcce4ce4a9a8aade9e177e90d47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_267f4770580e4b04877d6c635a49f0da",
              "IPY_MODEL_6cd08914df334d41a683f509e82e1929",
              "IPY_MODEL_69741605fc4d4bf9aa8239286ca820d5"
            ],
            "layout": "IPY_MODEL_a2cfdb3dc49d4ca7938d86a85505d5d7"
          }
        },
        "267f4770580e4b04877d6c635a49f0da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d24d80677dc74ad0a54e03ff33593692",
            "placeholder": "​",
            "style": "IPY_MODEL_72b649a03d7543b180ee511e2af83ab7",
            "value": "Downloading config.json: 100%"
          }
        },
        "6cd08914df334d41a683f509e82e1929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dac29984102342088bde21feb68865a2",
            "max": 474,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1b7a74d2f084aeab2651199426f4ca2",
            "value": 474
          }
        },
        "69741605fc4d4bf9aa8239286ca820d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24a76699b4264b899540156622b588c4",
            "placeholder": "​",
            "style": "IPY_MODEL_7efb3fe9f5904ecc8f8a6b2f7bc0bf4f",
            "value": " 474/474 [00:00&lt;00:00, 15.7kB/s]"
          }
        },
        "a2cfdb3dc49d4ca7938d86a85505d5d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d24d80677dc74ad0a54e03ff33593692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72b649a03d7543b180ee511e2af83ab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dac29984102342088bde21feb68865a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1b7a74d2f084aeab2651199426f4ca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24a76699b4264b899540156622b588c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7efb3fe9f5904ecc8f8a6b2f7bc0bf4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3cec38c2e5b4ef9852d209f0f2f68b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92ef805cc3b5491694134b69b1be00ea",
              "IPY_MODEL_72035406480f40919a8e457813dd257f",
              "IPY_MODEL_aafcd91992ae49db8e89c0e84e7c836a"
            ],
            "layout": "IPY_MODEL_aa19ac20892144cd90c87475096e5054"
          }
        },
        "92ef805cc3b5491694134b69b1be00ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a330db464a4844d8a1dedf4a19a71bcc",
            "placeholder": "​",
            "style": "IPY_MODEL_eb0d1186ce9c4306a8b9bbfba486438b",
            "value": "Downloading vocab.json: 100%"
          }
        },
        "72035406480f40919a8e457813dd257f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_faa11f9ebe134d44937ecd353ce8e4e2",
            "max": 898825,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d1913d29b254b59815e9883e973672d",
            "value": 898825
          }
        },
        "aafcd91992ae49db8e89c0e84e7c836a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb35c7f8de9e4a5e94eed3f54c271e63",
            "placeholder": "​",
            "style": "IPY_MODEL_e9b55786c09f4687a14914c6b2f0f5ca",
            "value": " 878k/878k [00:00&lt;00:00, 2.77MB/s]"
          }
        },
        "aa19ac20892144cd90c87475096e5054": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a330db464a4844d8a1dedf4a19a71bcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb0d1186ce9c4306a8b9bbfba486438b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "faa11f9ebe134d44937ecd353ce8e4e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d1913d29b254b59815e9883e973672d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb35c7f8de9e4a5e94eed3f54c271e63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9b55786c09f4687a14914c6b2f0f5ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dccd6a39438418392dd4ac4a5d6e961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_545805aab9be4e9d8e795d467aa99846",
              "IPY_MODEL_d2a6c8c5323043b2912daa2ac44fb324",
              "IPY_MODEL_d15091f26e0140a385ea4b2ad3b74cd3"
            ],
            "layout": "IPY_MODEL_bd9980a9e0f84ca3b2729432b6d71c29"
          }
        },
        "545805aab9be4e9d8e795d467aa99846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f9e956e7cec4c6cb76d92b2615a2caa",
            "placeholder": "​",
            "style": "IPY_MODEL_534037877e88475eb079713da35abac9",
            "value": "Downloading merges.txt: 100%"
          }
        },
        "d2a6c8c5323043b2912daa2ac44fb324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d6af7d6855241b5a66c1bdd7d0bc044",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_242f0dd48a424b2e8e75999a2f32b9d4",
            "value": 456318
          }
        },
        "d15091f26e0140a385ea4b2ad3b74cd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68a516ff50194f0bbe50f397107c781c",
            "placeholder": "​",
            "style": "IPY_MODEL_d4c409c3314e4bc8b90df00665ff2676",
            "value": " 446k/446k [00:00&lt;00:00, 852kB/s]"
          }
        },
        "bd9980a9e0f84ca3b2729432b6d71c29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f9e956e7cec4c6cb76d92b2615a2caa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "534037877e88475eb079713da35abac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d6af7d6855241b5a66c1bdd7d0bc044": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "242f0dd48a424b2e8e75999a2f32b9d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68a516ff50194f0bbe50f397107c781c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4c409c3314e4bc8b90df00665ff2676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7157dfe07724d75bebd7cb8a0d2ec51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3dbb4229b44b40b0a97f6af6577a496e",
              "IPY_MODEL_c4bb2c9150f24803be479774273adf2a",
              "IPY_MODEL_26c21835763b41d18760cd41620b56c1"
            ],
            "layout": "IPY_MODEL_0148b881295042259aa25bdc920d28c8"
          }
        },
        "3dbb4229b44b40b0a97f6af6577a496e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b7e0c7618a64dd189209c7e5a414f19",
            "placeholder": "​",
            "style": "IPY_MODEL_8fc94f8eb9e44d939974d1d7be01bca6",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "c4bb2c9150f24803be479774273adf2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f208568480446f7bb20361771935a7b",
            "max": 558614189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55ad7b2237ce41d5857e984a57fad74d",
            "value": 558614189
          }
        },
        "26c21835763b41d18760cd41620b56c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbddc1bcb8514416bda10aebb0acc07f",
            "placeholder": "​",
            "style": "IPY_MODEL_3fa0abc05cbe49dda357146118d2e278",
            "value": " 533M/533M [00:12&lt;00:00, 45.1MB/s]"
          }
        },
        "0148b881295042259aa25bdc920d28c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b7e0c7618a64dd189209c7e5a414f19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fc94f8eb9e44d939974d1d7be01bca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f208568480446f7bb20361771935a7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55ad7b2237ce41d5857e984a57fad74d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbddc1bcb8514416bda10aebb0acc07f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fa0abc05cbe49dda357146118d2e278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "> **University of Pisa - M.Sc. Computer Science, Artificial Intelligence**  \n",
        "> **Human Language Technologies - a.a. 2021/22**\n",
        ">\n",
        "> *September, 2022*\n",
        ">\n",
        ">**Authors** \n",
        "- Irene Pisani *i.pisani1@studenti.unipi.it* (560104)\n",
        "- Alice Bergonzini *a.bergonzini1@studenti.unipi.it* (560680)\n",
        "\n",
        "\n",
        "###### **FINAL PROJECT on KEY POINT ANALYSIS (KPA)**\n",
        "# **Track 2: Key Point Matching**\n",
        "\n",
        "***Abstract.*** This work aims to describe simple approaches for solving *Key Point Matching* (KPM) and *Key Point Generation* (KPG) tracks proposed at Argument Mining 2021 in the context of the shared task on *Quantitative Summarization and Key Point Analysis* (KPA). \\\n",
        "The presented methods rely on the fine-tuning of some state-of-the-art pre-trained language models both for KPM and KPG subtasks. \\\n",
        "Regarding the KPM task all the models explored were validated using the Hold-Out validation technique and their results were compared to analyze their effectiveness within the task.  Leveraging DeBERTa pre-trained transformer, our best model yields to competitive performance since it achieved  on the test set a mAP Strict and mAP Relaxed score of, respectively, 0,7035 and 0,8857. \\\n",
        " For the KPG task, a simple baseline based on abstractive summarization approach was provided; our system takes advantage of the pre-trained Google mT5 transformer to generate several points that are finally properly selected."
      ],
      "metadata": {
        "id": "W6SVrMI41lP6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Settings**\n",
        "\n",
        "- Define Colab GPU to use\n",
        "- Download TR, VL e TS set from offial IBM reporsitory\n",
        "- Install some required tools and libraries"
      ],
      "metadata": {
        "id": "ZPit-0frpOlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM556-4Gp-Mz",
        "outputId": "7db028e7-9d6c-49eb-d17a-c55c09241d48"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Aug 28 10:12:48 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BokHbFb2i4qB",
        "outputId": "2045d975-8c6d-4132-b56e-ed0c40029bcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'KPA_2021_shared_task'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 44 (delta 14), reused 26 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (44/44), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone \"https://github.com/IBM/KPA_2021_shared_task\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VxXARfVj6OI",
        "outputId": "3b9a5294-9154-4c0f-8881-9bf4e6cebd4e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 50.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 44.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Argument Mining KPA 2021: Function provided for standard evaluation method**\n",
        "- Load dataset (TR, VL e tS)\n",
        "- Load predictions stored in json file\n",
        "- Evaluate predictions with official KPA-2021 metrics:mAP strict and mAP relaxed"
      ],
      "metadata": {
        "id": "5ua15ByQpXf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score, precision_score\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "\n",
        "# this function are not written by us: they are provided by the ArgMining KPA 2021 Shared task\n",
        "# source\n",
        "# we use this function to homologate our evaluation methos to one used in Shared task\n",
        "\n",
        "def get_ap(df, label_column, top_percentile=0.5):\n",
        "    top = int(len(df)*top_percentile)\n",
        "    df = df.sort_values('score', ascending=False).head(top)\n",
        "    # after selecting top percentile candidates, we set the score for the dummy kp to 1, to prevent it from increasing the precision.\n",
        "    df.loc[df['key_point_id'] == \"dummy_id\", 'score'] = 0.99\n",
        "    ap = average_precision_score(y_true=df[label_column], y_score=df[\"score\"])\n",
        "    # multiply by the number of positives in top 50% and devide by the number of max positives within the top 50%, which is the number of top 50% instances\n",
        "    positives_in_top_predictions = sum(df[label_column])\n",
        "    max_num_of_positives = len(df)\n",
        "    ap_retrieval = ap * positives_in_top_predictions/max_num_of_positives\n",
        "    return ap_retrieval\n",
        "\n",
        "def calc_mean_average_precision(df, label_column):\n",
        "    precisions = [get_ap(group, label_column) for _, group in df.groupby([\"topic\", \"stance\"])]\n",
        "    return np.mean(precisions)\n",
        "\n",
        "def evaluate_predictions(merged_df):\n",
        "    #print(\"\\n** running evalution:\")\n",
        "    mAP_strict = calc_mean_average_precision(merged_df, \"label_strict\")\n",
        "    mAP_relaxed = calc_mean_average_precision(merged_df, \"label_relaxed\")\n",
        "    #print(f\"mAP strict= {mAP_strict} ; mAP relaxed = {mAP_relaxed}\")\n",
        "    return mAP_strict, mAP_relaxed\n",
        "\n",
        "def load_kpm_data(gold_data_dir, subset, submitted_kp_file=None):\n",
        "    #print(\"\\nֿ** loading task data:\")\n",
        "    arguments_file = os.path.join(gold_data_dir, f\"arguments_{subset}.csv\")\n",
        "    if not submitted_kp_file:\n",
        "        key_points_file = os.path.join(gold_data_dir, f\"key_points_{subset}.csv\")\n",
        "    else:\n",
        "        key_points_file=submitted_kp_file\n",
        "    labels_file = os.path.join(gold_data_dir, f\"labels_{subset}.csv\")\n",
        "\n",
        "\n",
        "    arguments_df = pd.read_csv(arguments_file)\n",
        "    key_points_df = pd.read_csv(key_points_file)\n",
        "    labels_file_df = pd.read_csv(labels_file)\n",
        "\n",
        "\n",
        "    for desc, group in arguments_df.groupby([\"stance\", \"topic\"]):\n",
        "        stance = desc[0]\n",
        "        topic = desc[1]\n",
        "        key_points = key_points_df[(key_points_df[\"stance\"] == stance) & (key_points_df[\"topic\"] == topic)]\n",
        "        #print(f\"\\t{desc}: loaded {len(group)} arguments and {len(key_points)} key points\")\n",
        "    return arguments_df, key_points_df, labels_file_df\n",
        "\n",
        "\n",
        "def get_predictions(predictions_file, labels_df, arg_df, kp_df):\n",
        "    #print(\"\\nֿ** loading predictions:\")\n",
        "    arg_df = arg_df[[\"arg_id\", \"topic\", \"stance\"]]\n",
        "    predictions_df = load_predictions(predictions_file, kp_df[\"key_point_id\"].unique())\n",
        "\n",
        "    #make sure each arg_id has a prediction\n",
        "    predictions_df = pd.merge(arg_df, predictions_df, how=\"left\", on=\"arg_id\")\n",
        "    #print(predictions_df[predictions_df.isna().any(axis=1)])\n",
        "    #handle arguements with no matching key point\n",
        "    predictions_df[\"key_point_id\"] = predictions_df[\"key_point_id\"].fillna(\"dummy_id\")\n",
        "    predictions_df[\"score\"] = predictions_df[\"score\"].fillna(0)\n",
        "\n",
        "    #merge each argument with the gold labels\n",
        "    merged_df = pd.merge(predictions_df, labels_df, how=\"left\", on=[\"arg_id\", \"key_point_id\"])\n",
        "\n",
        "    merged_df.loc[merged_df['key_point_id'] == \"dummy_id\", 'label'] = 0\n",
        "    merged_df[\"label_strict\"] = merged_df[\"label\"].fillna(0)\n",
        "    merged_df[\"label_relaxed\"] = merged_df[\"label\"].fillna(1)\n",
        "\n",
        "    return merged_df\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "this method chooses the best key point for each argument\n",
        "and generates a dataframe with the matches and scores\n",
        "\"\"\"\n",
        "def load_predictions(predictions_dir, correct_kp_list):\n",
        "    arg =[]\n",
        "    kp = []\n",
        "    scores = []\n",
        "    invalid_keypoints = set()\n",
        "    with open(predictions_dir, \"r\") as f_in:\n",
        "        res = json.load(f_in)\n",
        "        for arg_id, kps in res.items():\n",
        "            valid_kps = {key: value for key, value in kps.items() if key in correct_kp_list}\n",
        "            invalid = {key: value for key, value in kps.items() if key not in correct_kp_list}\n",
        "            for invalid_kp, _ in invalid.items():\n",
        "                if invalid_kp not in invalid_keypoints:\n",
        "                    #print(f\"key point {invalid_kp} doesn't appear in the key points file and will be ignored\")\n",
        "                    invalid_keypoints.add(invalid_kp)\n",
        "            if valid_kps:\n",
        "                best_kp = max(valid_kps.items(), key=lambda x: x[1])\n",
        "                arg.append(arg_id)\n",
        "                kp.append(best_kp[0])\n",
        "                scores.append(best_kp[1])\n",
        "        #print(f\"\\tloaded predictions for {len(arg)} arguments\")\n",
        "        return pd.DataFrame({\"arg_id\" : arg, \"key_point_id\": kp, \"score\": scores})"
      ],
      "metadata": {
        "id": "tpJgvKL1i-Dj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Parser class**\n",
        "\n",
        "- Dataset pre-processing (lower case and punctuations removal)\n",
        "- Create a first dataset with <argument, keypoint> pairs having annotated label (0,1)\n",
        "- Create a second dataset with <argument, keypoint> pairs having annotated label (0,1, undecided)\n",
        "- Execute tokenization of both dataset"
      ],
      "metadata": {
        "id": "yGLkyccHpoxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "class DatasetParser():\n",
        "  \n",
        "  def __init__(self, tokenizer_name):\n",
        "\n",
        "    self.arguments = None     # dataframe of arguments: [arg_id, argument, topic, stance]\n",
        "    self.keypoints = None     # dataframe of keypoints: [kp_id, key_point, topic, stance]\n",
        "    self.labels    = None     # dataframe of labels:    [arg_id, kp_id, label]\n",
        "    \n",
        "    self.merged_dataset    = None     # dataframe of merged information: [arg_id, argument, kp_id, key_points, topic, stance, label]\n",
        "    self.tokenized_dataset = None     # tensor dataset: [ids, token_types_info, attention_mask, stance, label]\n",
        "    self.preds = None                 # dataframe dataset to store model predictions, also pairs with undecided label are reported here\n",
        "    self.tokenized_preds = None       # tensor dataset: [ids, token_types_info, attention_mask, stance, label]\n",
        "\n",
        "    self.lemmatizer = WordNetLemmatizer()               # lemmatizer object loaded from nltk \n",
        "    self.stemmer    = PorterStemmer()                   # Stemmer object loaded from nltk \n",
        "    self.stop_words = set(stopwords.words(\"english\"))   # set of stopwords for english language\n",
        "\n",
        "    # tokenizer object loaded from hugging face pretrained tokenizer\n",
        "    self.tokenizer_name = tokenizer_name\n",
        "    self.tokenizer      = AutoTokenizer.from_pretrained(self.tokenizer_name) \n",
        "\n",
        "  # -------------------- Execute preprocessing and data cleaning on textual information ----------------------------------------\n",
        "\n",
        "  def remove_punctuations(self, text):\n",
        "    return re.sub(r'[^\\w\\s]', ' ', text)\n",
        "\n",
        "  def remove_stopwords(self,text):\n",
        "    return ' '.join([word for word in nltk.word_tokenize(text) if word not in self.stop_words])\n",
        "  \n",
        "  def lemmatize_words(self, text): #ot used\n",
        "    return ' '.join(self.lemmatizer.lemmatize(word) for word in text.split())\n",
        "  \n",
        "  def stemming_words(self, text): # not used\n",
        "    return ' '.join(self.stemmer.stem(word) for word in text.split())\n",
        "  \n",
        "  def lower_case(self, text):           \n",
        "    return text.lower()\n",
        "  \n",
        "  def ohe_stance (self, stance):\n",
        "    if stance == -1:\n",
        "      return 0 \n",
        "    else:\n",
        "      return 1\n",
        "  \n",
        "  def preprocess_data(self):\n",
        "\n",
        "    # used preprocessing technique: lower case, remove punctuations.\n",
        "    \n",
        "    # execute data preprocessing on arguments\n",
        "    self.arguments[\"stance\"] = self.arguments[\"stance\"].apply(self.ohe_stance)               # one hot encoder over stance\n",
        "    self.arguments[\"argument\"] = self.arguments[\"argument\"].apply(self.lower_case)           # trasform to lower case\n",
        "    #self.arguments[\"argument\"] = self.arguments[\"argument\"].apply(self.remove_stopwords)     # remove stop words \n",
        "    self.arguments[\"argument\"] = self.arguments[\"argument\"].apply(self.remove_punctuations)  # remove punctuations\n",
        "    #self.arguments[\"argument\"] = self.arguments[\"argument\"].apply(self.lemmatize_words)      # lemmatize words\n",
        "    self.arguments[\"topic\"] = self.arguments[\"topic\"].apply(self.lower_case)           # trasform to lower case\n",
        "    #self.arguments[\"topic\"] = self.arguments[\"topic\"].apply(self.remove_stopwords)     # remove stop words \n",
        "    self.arguments[\"topic\"] = self.arguments[\"topic\"].apply(self.remove_punctuations)  # remove punctuations\n",
        "    #self.arguments[\"topic\"] = self.arguments[\"topic\"].apply(self.lemmatize_words)      # lemmatize words\n",
        "\n",
        "    # execute data preprocessing on keypoints\n",
        "    self.keypoints[\"stance\"] = self.keypoints[\"stance\"].apply(self.ohe_stance)                # one hot encoder over stance\n",
        "    self.keypoints[\"key_point\"] = self.keypoints[\"key_point\"].apply(self.lower_case)          # trasform to lower case\n",
        "    #self.keypoints[\"key_point\"] = self.keypoints[\"key_point\"].apply(self.remove_stopwords)    # remove stop words \n",
        "    self.keypoints[\"key_point\"] = self.keypoints[\"key_point\"].apply(self.remove_punctuations) # remove punctuations\n",
        "    #self.keypoints[\"key_point\"] = self.keypoints[\"key_point\"].apply(self.lemmatize_words)     # lemmatize words\n",
        "    self.keypoints[\"topic\"] = self.keypoints[\"topic\"].apply(self.lower_case)          # trasform to lower case\n",
        "    #self.keypoints[\"topic\"] = self.keypoints[\"topic\"].apply(self.remove_stopwords)    # remove stop words \n",
        "    self.keypoints[\"topic\"] = self.keypoints[\"topic\"].apply(self.remove_punctuations) # remove punctuations\n",
        "    #self.keypoints[\"topic\"] = self.keypoints[\"topic\"].apply(self.lemmatize_words)     # lemmatize words\n",
        "\n",
        "    return \n",
        "  \n",
        "  # -------------------- Create a dataset merging information from arguments, keypoints and labels ----------------------------------------\n",
        "\n",
        "  def get_merged_dataset (self):\n",
        "\n",
        "    # create a merged dataset with all <argument, keypoint> pairs for which an annotated label (0 or 1) exist\n",
        "    # do not consider <argument, keypoint> pairs with undecided label\n",
        "    \n",
        "    self.merged_dataset = self.labels.merge(self.arguments, on=\"arg_id\")\n",
        "    self.merged_dataset = self.merged_dataset.merge(self.keypoints, on = \"key_point_id\")\n",
        "    self.merged_dataset.drop([\"stance_x\", \"topic_x\"], axis=1, inplace=True)\n",
        "    self.merged_dataset = self.merged_dataset.rename(columns={\"stance_y\":\"stance\", \"topic_y\":\"topic\"})\n",
        "\n",
        "    return\n",
        "\n",
        "  # -------------------- Tokenize dataset to properly feed it to the model -----------------------------------------------------------------\n",
        "  \n",
        "  def get_tokenized_dataset (self ): \n",
        "    \n",
        "    input_ids = []\n",
        "    input_tti = []\n",
        "    input_mask = []\n",
        "    input_stance = []\n",
        "    input_label = []\n",
        "\n",
        "    # apply tokenization on all pairs <(argument+topic), keypoint> for \n",
        "    for i in range(len(self.merged_dataset)):\n",
        "      \n",
        "      encoded_input = self.tokenizer(self.merged_dataset[\"argument\"][i] + self.merged_dataset[\"topic\"][i],\n",
        "                                     self.merged_dataset[\"key_point\"][i],\n",
        "                                     add_special_tokens = True, \n",
        "                                     max_length = 80, \n",
        "                                     padding = \"max_length\")\n",
        "      \n",
        "      input_ids.append(encoded_input[\"input_ids\"])\n",
        "      if self.tokenizer_name.startswith(\"bert-\") == True:\n",
        "        input_tti.append(encoded_input[\"token_type_ids\"])\n",
        "      input_mask.append(encoded_input[\"attention_mask\"])\n",
        "      input_stance.append(self.merged_dataset[\"stance\"][i])\n",
        "      input_label.append(self.merged_dataset[\"label\"][i])\n",
        "\n",
        "    # trasnform to tensors\n",
        "    input_ids = torch.tensor(input_ids).squeeze()  \n",
        "    input_mask = torch.tensor(input_mask).squeeze()\n",
        "    input_stance = torch.tensor(input_stance).squeeze()\n",
        "    input_label = torch.tensor(input_label).squeeze()\n",
        "    \n",
        "    # use token type id only if the used tokenizer is the bert tokenizer\n",
        "    # create the final tokeinzed dataset made up with tensors \n",
        "    if self.tokenizer_name.startswith(\"bert-\") == True:\n",
        "      input_tti = torch.tensor(input_tti).squeeze()\n",
        "      self.tokenized_dataset = TensorDataset(input_ids, input_tti, input_mask, input_stance, input_label)\n",
        "    else:\n",
        "      self.tokenized_dataset = TensorDataset(input_ids, input_mask, input_stance, input_label)\n",
        "\n",
        "    return\n",
        "\n",
        "    \n",
        "  def get_tokenized_preds (self): \n",
        "    \n",
        "    # do the same tokenization procedure reported above \n",
        "    # here use dataset composed by all <argument keypoint> pairs, also the pairs labelled with undecided\n",
        "    \n",
        "    input_ids = []\n",
        "    input_tti = []\n",
        "    input_mask = []\n",
        "    input_stance = []\n",
        "  \n",
        "    for i in range(len(self.preds)):\n",
        "      \n",
        "      encoded_input = self.tokenizer(self.preds[\"argument\"][i] + self.preds[\"topic\"][i],\n",
        "                                     self.preds[\"key_point\"][i],\n",
        "                                     add_special_tokens = True, \n",
        "                                     max_length = 80, \n",
        "                                     padding = \"max_length\")\n",
        "      \n",
        "      input_ids.append(encoded_input[\"input_ids\"])\n",
        "      if self.tokenizer_name.startswith(\"bert-\") == True:\n",
        "        input_tti.append(encoded_input[\"token_type_ids\"])\n",
        "      input_mask.append(encoded_input[\"attention_mask\"])\n",
        "      input_stance.append(self.preds[\"stance\"][i])\n",
        "\n",
        "    input_ids = torch.tensor(input_ids).squeeze()  \n",
        "    input_mask = torch.tensor(input_mask).squeeze()\n",
        "    input_stance = torch.tensor(input_stance).squeeze()\n",
        "    \n",
        "    if self.tokenizer_name.startswith(\"bert-\") == True:\n",
        "      input_tti = torch.tensor(input_tti).squeeze()\n",
        "      self.tokenized_preds = TensorDataset(input_ids, input_tti, input_mask, input_stance)\n",
        "    else:\n",
        "      self.tokenized_preds= TensorDataset(input_ids, input_mask, input_stance)\n",
        "\n",
        "    return\n",
        "  \n",
        "  def get_preds(self):\n",
        "\n",
        "    arg_pred = []\n",
        "    key_point_pred = []\n",
        "\n",
        "    arg_id_pred = []\n",
        "    key_point_id_pred = []\n",
        "    stance = []\n",
        "    topic = []\n",
        "\n",
        "    # crate a dataset to use to evualate the model (not for training)\n",
        "    # this dataset is composed by all <argument, keypoint> pairs and include also pairs labelled as undecided \n",
        "    # the pair labelled with undecided have NaN label\n",
        "\n",
        "    for arg,arg_id,topic_arg,stance_arg  in zip(self.arguments['argument'],self.arguments['arg_id'],self.arguments['topic'],self.arguments['stance']):\n",
        "      for kp,kp_id,topic_kp,stance_kp in zip(self.keypoints['key_point'],self.keypoints['key_point_id'],self.keypoints['topic'],self.keypoints['stance']):\n",
        "        if ( topic_arg == topic_kp and stance_arg == stance_kp):\n",
        "          \n",
        "          arg_pred.append(arg)\n",
        "          arg_id_pred.append(arg_id)\n",
        "          key_point_pred.append(kp)\n",
        "          key_point_id_pred.append(kp_id)\n",
        "          topic.append(topic_arg)\n",
        "          stance.append(stance_arg)\n",
        "\n",
        "    self.preds = pd.DataFrame({'arg_id':arg_id_pred,'key_point_id':key_point_id_pred,'argument':arg_pred, 'key_point':key_point_pred, 'topic' : topic , 'stance': stance})\n",
        "    \n",
        "    return\n",
        "  \n",
        "  # -------------------- execute all preprocessing --------------------\n",
        "  \n",
        "  def get_data (self, data_directory, mode):\n",
        "\n",
        "    # Load dataset using the official ArgMining function\n",
        "    self.arguments, self.keypoints, self.labels = load_kpm_data(data_directory, mode)\n",
        "    print(mode+\" data has been loaded\")\n",
        "\n",
        "    # Execute data preprocessing and cleaning\n",
        "    self.preprocess_data()\n",
        "    print(mode+\" data has been preprocessed\")\n",
        "\n",
        "    # Create a dataset with pairs <argument, keypoint> obtained merging information from argumets, keypoints and labels\n",
        "    self.get_merged_dataset()\n",
        "    print(mode+\" dataset has been created\")\n",
        "\n",
        "    # tokenize the already created dataset\n",
        "    self.get_tokenized_dataset()\n",
        "    print(mode+\" dataset has been tokenized and transformed to tensors\")\n",
        "\n",
        "    # Create a dataset with pairs <argument, keypoint> obtained merging information from argumets, keypoints\n",
        "    self.get_preds()\n",
        "    print(mode+\" predictions file has been created\")\n",
        "\n",
        "    # tokenize the already created dataset\n",
        "    self.get_tokenized_preds()\n",
        "    print(mode+\" tokenized predictions file has been created\\n\")\n",
        "\n",
        "    # return a dataset dictionary with each processed information\n",
        "    data_dict = {}\n",
        "    data_dict[\"arguments_df\"] = self.arguments                      # arguments set \n",
        "    data_dict[\"keypoints_df\"] = self.keypoints                      # keypoints set \n",
        "    data_dict[\"labels_df\"]    = self.labels                         # labels set \n",
        "\n",
        "    data_dict[\"merged_dataset_df\"]    = self.merged_dataset         # dataset 1: <argument, keypoint, label> set with label (0,1)\n",
        "    data_dict[\"tokenized_dataset_tensor\"] = self.tokenized_dataset  # tokenized dataset 1\n",
        "    data_dict[\"preds\"] = self.preds                                 # dataset 2: <argument, keypoint, label> set with label (0,1, undecided)\n",
        "    data_dict[\"tokenized_preds\"] = self.tokenized_preds             # tokenized dataset 2\n",
        "\n",
        "    return data_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8K17XY3i_F8",
        "outputId": "70b1f0ce-67a8-4e12-e121-f4c5381fab4f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Architecture class**\n",
        "\n",
        "- Define model's architecture (by using a pretrained transformer)\n",
        "- Define feed-forward procedure "
      ],
      "metadata": {
        "id": "UIXT3uQvqo4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "import torch.nn as nn\n",
        "\n",
        "# define model architecture to execute feed forward computations\n",
        "\n",
        "class Architecture (nn.Module):\n",
        "\n",
        "  def __init__(self, model_name, drop_out, out_unit_1):\n",
        "    super(Architecture, self).__init__()\n",
        "    \n",
        "    self.model_name = model_name    # bert, roberta, albert or deberta in base version\n",
        "    # transformer model \n",
        "    self.transformer_layer = AutoModel.from_pretrained(self.model_name)\n",
        "   \n",
        "    # add dense layers with dropuot\n",
        "    self.dense_layer_1 = nn.Linear(769, out_unit_1)\n",
        "    self.drop_out = nn.Dropout(drop_out)\n",
        "    self.dense_layer_2 = nn.Linear(out_unit_1, 1)\n",
        "\n",
        "    # apply sigmoid act. function in output (last dense layer)\n",
        "    self.act_function = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, ids, mask, stance, tti=None):\n",
        "    \n",
        "    # execute feed-forward \n",
        "\n",
        "    # manage transformer ouput based on the given transformer \n",
        "    if self.model_name.startswith(\"bert-\") == True:\n",
        "      x = self.transformer_layer(input_ids=ids, token_type_ids=tti, attention_mask = mask).pooler_output\n",
        "    else:\n",
        "      hidden_state = self.transformer_layer(input_ids=ids, attention_mask = mask)[0]\n",
        "      x = hidden_state[:,0]\n",
        "    \n",
        "    # concatenate transformer output with stance\n",
        "    stance = torch.reshape(stance, (len(stance), 1))\n",
        "    concat = torch.cat((x, stance), dim=1)\n",
        "    \n",
        "    x1 = self.dense_layer_1(concat)\n",
        "    x1 = self.drop_out(x1)\n",
        "    x2 = self.dense_layer_2(x1)\n",
        "    x2 = self.drop_out(x2)\n",
        "    \n",
        "    out = self.act_function(x2)\n",
        "    \n",
        "    return out"
      ],
      "metadata": {
        "id": "eLOaUO-_qn7E"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Metrics**\n",
        "- Monitor performance on TR set by computing classification report and confusion matrix\n",
        "- Monitor performannce on Vl e TS set by computing classification report, connfusion matrix and official KPA-2021 metrics (mAP strict and relaxed) "
      ],
      "metadata": {
        "id": "wZ8vjt0R4tal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "def compute_metrics (mode, df, filename, lbl_df, arg_df, kp_df):\n",
        "\n",
        "  # ----------------------------- Save predictions in json format -----------------------------\n",
        "  \n",
        "  # save all model predictions in json file\n",
        "  # for each argumennt save the matching score with the corresponding key points\n",
        "  args = {}\n",
        "  for arg_,kp_,score in zip(df['arg_id'],df['key_point_id'],df['predictions']):\n",
        "    args[arg_] = {}\n",
        "  for arg_,kp_,score in zip(df['arg_id'],df['key_point_id'],df['predictions']):\n",
        "    args[arg_][kp_] = score \n",
        "  with open(filename, 'w') as fp:\n",
        "    fp.write(json.dumps(args))\n",
        "    fp.close()\n",
        "\n",
        "  merged_df = get_predictions(filename, lbl_df, arg_df, kp_df)  #DF CON PREDICTION (ARG, KP, SCORE, LABEL)\n",
        "  \n",
        "  # choose metrics to evaluate quality of model's prediction \n",
        "\n",
        "\n",
        "  # ----------------------------- Metric to analyze TR performance -----------------------------\n",
        "  if mode==\"train\":\n",
        "    \n",
        "    merged_df.to_csv(\"prediction_results_TRAINING.csv\")\n",
        "    \n",
        "    # compute Classification Report (Accuracy, Precision, Recall, F1) and Confusion Matrix\n",
        "    merged_df['score'] = np.where(merged_df['score'] < 0.5, 0, 1) # put threshold to 0.5\n",
        "    cr = classification_report(merged_df[\"label\"].astype(int), merged_df[\"score\"])\n",
        "    cm = confusion_matrix(merged_df[\"label\"].astype(int), merged_df[\"score\"])\n",
        "    \n",
        "    return cr\n",
        "  # ----------------------------- Metric to analyze VL and TS performance -----------------------------\n",
        "  else: #mode==\"test\" or \"eval\"\n",
        "    \n",
        "    merged_df.to_csv(\"prediction_results_TEST.csv\")\n",
        "    \n",
        "    # compute mAP Strict and mAP Relaxed\n",
        "    mAP_strict, mAP_relaxed = evaluate_predictions(merged_df)\n",
        "    \n",
        "    # compute Accuracy, Precision, Recall, F1, Confusion Matrix\n",
        "    merged_df = merged_df.dropna() # not consider undecided label\n",
        "    merged_df['score'] = np.where(merged_df['score'] < 0.5, 0, 1) # put threshold to 0.5\n",
        "    cr = classification_report(merged_df[\"label\"].astype(int), merged_df[\"score\"]) \n",
        "    cm = confusion_matrix(merged_df[\"label\"].astype(int), merged_df[\"score\"])\n",
        "    \n",
        "    return cr, cm, mAP_strict, mAP_relaxed\n"
      ],
      "metadata": {
        "id": "NwCXiejBq3eu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Trainer class**\n",
        "- Define a trainer object to perform model's finetuning\n",
        "  - Use training function to fine-tune the model on TR set\n",
        "  - Use evaluate function to evaluate model behaviour on VL set during fine-tuning stes.\n",
        "  - use fit function to runs all these mentioned procedures"
      ],
      "metadata": {
        "id": "_mb6JpyUq4Op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import LinearLR\n",
        "from  torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils import shuffle, class_weight\n",
        "\n",
        "\n",
        "\n",
        "class Trainer():\n",
        "  \n",
        "  def __init__(self, model_name, model_checkpoint, train_data_dict, val_data_dict, param):\n",
        "    \n",
        "    # inizialize model and device\n",
        "    self.model_name = model_name\n",
        "\n",
        "    # get hypeparameter values\n",
        "    self.epochs        = param[\"epochs\"]\n",
        "    self.batch_size    = param[\"batch_size\"]\n",
        "    self.learning_rate = param[\"learning_rate\"]\n",
        "    self.total_iters   = 5\n",
        "    self.dropout       = param[\"drop_out\"]\n",
        "    self.n_out_unit_1  = param[\"unit_1\"]\n",
        "\n",
        "    if model_checkpoint == None:\n",
        "      #  build model architecture\n",
        "      self.model = Architecture(self.model_name, self.dropout, self.n_out_unit_1)\n",
        "      self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "    else:\n",
        "      # load model from checkpoint \n",
        "      self.model = torch.load(model_checkpoint)\n",
        "      self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "    self.model.to(self.device) # pass model to gpu \n",
        "\n",
        "    # define TRAINING DATA \n",
        "    self.tr_arguments = train_data_dict[\"arguments_df\"]\n",
        "    self.tr_keypoints = train_data_dict[\"keypoints_df\"]\n",
        "    self.tr_labels    = train_data_dict[\"labels_df\"]\n",
        "    self.tr_merged    = train_data_dict[\"merged_dataset_df\"]\n",
        "    self.tr_dataset   = train_data_dict[\"tokenized_dataset_tensor\"]\n",
        "\n",
        "    # define VALIDATION DATA\n",
        "    if val_data_dict != None: \n",
        "      self.vl_arguments = val_data_dict[\"arguments_df\"]\n",
        "      self.vl_keypoints = val_data_dict[\"keypoints_df\"]\n",
        "      self.vl_labels    = val_data_dict[\"labels_df\"]\n",
        "      self.vl_merged    = val_data_dict[\"merged_dataset_df\"]\n",
        "      self.vl_dataset   = val_data_dict[\"tokenized_dataset_tensor\"]\n",
        "      self.vl_merged_pred    = val_data_dict[\"preds\"]\n",
        "      self.vl_dataset_pred   = val_data_dict[\"tokenized_preds\"]\n",
        "\n",
        "    self.tr_dataloader = None  # define null dataloader object for training\n",
        "    self.vl_dataloader = None  # define null dataloader object for validation\n",
        "    self.vl_dataloader_pred = None  # define null dataloader object for validation also for undediced label\n",
        "    \n",
        "    self.loss_function = nn.BCELoss()\n",
        "    self.optimizer = optim.AdamW(self.model.parameters(), \n",
        "                                 lr=self.learning_rate, \n",
        "                                 weight_decay = 0.01)\n",
        "    self.scheduler = LinearLR(self.optimizer)\n",
        "\n",
        "    self.tr_loss, self.tr_cr = None, None\n",
        "    self.vl_loss, self.vl_cr, self.vl_map_strict, self.vl_map_relaxed = None, None, None, None\n",
        "\n",
        "    self.history = {\"tr_loss\":[], \"tr_cr\":[],\n",
        "                    \"vl_loss\":[], \"vl_cr\":[], \"vl_map_strict\":[], \"vl_map_relaxed\":[]}\n",
        "      \n",
        "    \n",
        "  # ---------------------------------------- FINETUNING on TR set  ------------------------------\n",
        "  def training(self):\n",
        "    self.model.train()     # set model state in training mode\n",
        "    print(\"Training started!!\")\n",
        "    running_loss = 0  # accumulate computed loss for each batch\n",
        "    running_acc  = 0  # accumulate computed accuracy for each batch\n",
        "    epoch_preds = []\n",
        "\n",
        "    # iterate over batches\n",
        "    for batch, dl in enumerate(self.tr_dataloader): \n",
        "\n",
        "      if self.model_name.startswith(\"bert-\")==True:\n",
        "      # define input features in the current batches and move it to the employed device\n",
        "        ids, tti, mask, stance, label = dl  \n",
        "        ids = ids.to(self.device)        # feature 1 = ids\n",
        "        tti = tti.to(self.device)        # feature 2 = token types ids\n",
        "        mask = mask.to(self.device)      # feature 3 = attention mask\n",
        "        stance = stance.to(self.device)  # feature 4 = stance\n",
        "        label = label.to(self.device)    # target = label\n",
        "      else:\n",
        "        ids, mask, stance, label = dl  \n",
        "        ids = ids.to(self.device)        # feature 1 = ids\n",
        "        mask = mask.to(self.device)      # feature 3 = attention mask\n",
        "        stance = stance.to(self.device)  # feature 4 = stance\n",
        "        label = label.to(self.device)  \n",
        "\n",
        "      self.optimizer.zero_grad() #clear previously computed gradients\n",
        "      \n",
        "      # ---------- FORWARD ----------\n",
        "      # compute model's output (this is matching score for each sample in the current batch)\n",
        "      if self.model_name.startswith(\"bert-\")==True:\n",
        "        output = self.model (ids, mask, stance, tti)     \n",
        "      else:\n",
        "        output = self.model(ids, mask, stance) \n",
        "     \n",
        "      # compute loss for the current batches\n",
        "      label = torch.reshape(label, (label.shape[0], 1)).float() \n",
        "      loss = self.loss_function(output, label)\n",
        "      \n",
        "      # ---------- BACKWARD ----------\n",
        "      loss.backward() # backpropagate loss\n",
        "      # clip gradient to prevent exploding gradients\n",
        "      torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0) \n",
        "      self.optimizer.step() # update model parameter\n",
        "      self.scheduler.step() # update learning rate value\n",
        "      \n",
        "      # ---------- METRICS ----------\n",
        "      # accumulate loss of each batch\n",
        "      running_loss+=loss.item()\n",
        "      # accumulate predictions (matching score) of each batch\n",
        "      pred = output.detach().cpu().numpy()\n",
        "      pred = np.hstack(pred)\n",
        "      epoch_preds.append(pred)\n",
        "\n",
        "    # compute loss, classification report, map strict, map relaxed for the whole training epoch\n",
        "    epoch_preds = np.concatenate(epoch_preds, axis=0)\n",
        "    self.tr_merged[\"predictions\"] = epoch_preds\n",
        "    self.tr_cr = compute_metrics(\"train\",\n",
        "                                 self.tr_merged,\n",
        "                                      \"predictions_tr.p.\",\n",
        "                                      self.tr_labels,\n",
        "                                      self.tr_arguments, \n",
        "                                      self.tr_keypoints)\n",
        "    \n",
        "    self.tr_loss = running_loss/len(self.tr_dataloader)\n",
        "    \n",
        "    return\n",
        "  # ---------------------------------------- EVALUATION on VL set  ------------------------------\n",
        "  def evaluation(self):\n",
        "\n",
        "    epoch_preds = []\n",
        "    epoch_preds_map = []\n",
        "    \n",
        "    self.model.eval()\n",
        "    print(\"Evaluating...\")\n",
        "    running_loss = 0  # accumulate computed loss for each batch\n",
        "   \n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # use dataset with only pairs havinng (0,1) label to compute vl loss\n",
        "      for batch, dl in enumerate(self.vl_dataloader):\n",
        "        \n",
        "        if self.model_name.startswith(\"bert-\")==True:\n",
        "          ids, tti, mask, stance, label = dl\n",
        "          ids = ids.to(self.device)\n",
        "          tti = tti.to(self.device)\n",
        "          mask = mask.to(self.device)\n",
        "          stance = stance.to(self.device)\n",
        "          label = label.to(self.device)\n",
        "\n",
        "          output = self.model (ids, mask, stance, tti)\n",
        "        else:\n",
        "          ids, mask, stance, label = dl\n",
        "          ids = ids.to(self.device)\n",
        "          mask = mask.to(self.device)\n",
        "          stance = stance.to(self.device)\n",
        "          label = label.to(self.device)\n",
        "\n",
        "          output = self.model (ids, mask, stance)\n",
        "        \n",
        "        label = torch.reshape(label, (label.shape[0], 1)).float() \n",
        "        loss = self.loss_function(output, label)\n",
        "        running_loss+=loss.item()\n",
        "        \n",
        "        pred = output.detach().cpu().numpy()\n",
        "        pred = np.hstack(pred)\n",
        "        epoch_preds.append(pred)\n",
        "      \n",
        "      # this is NOT a good procedure but here we need it to not rewrite all code structures and still compute loss and others metrics\n",
        "      # the use dataset with only pairs havinng (0,1, undecided) label to compute all others metrics\n",
        "      for batch, dl in enumerate(self.vl_dataloader_pred):\n",
        "        \n",
        "        if self.model_name.startswith(\"bert-\")==True:\n",
        "          ids, tti, mask, stance = dl\n",
        "          ids = ids.to(self.device)\n",
        "          tti = tti.to(self.device)\n",
        "          mask = mask.to(self.device)\n",
        "          stance = stance.to(self.device)\n",
        "\n",
        "          output = self.model (ids, mask, stance, tti)\n",
        "        else:\n",
        "          ids, mask, stance = dl\n",
        "          ids = ids.to(self.device)\n",
        "          mask = mask.to(self.device)\n",
        "          stance = stance.to(self.device)\n",
        "\n",
        "          output = self.model (ids, mask, stance)\n",
        "        \n",
        "        pred = output.detach().cpu().numpy()\n",
        "        pred = np.hstack(pred)\n",
        "        epoch_preds_map.append(pred)\n",
        "    \n",
        "    # compute map and classification report\n",
        "    epoch_preds = np.concatenate(epoch_preds, axis=0)\n",
        "    self.vl_merged[\"predictions\"] = epoch_preds\n",
        "    self.vl_cr = compute_metrics(\"train\",\n",
        "                                      self.vl_merged,\n",
        "                                      \"predictions_tr.p.\",\n",
        "                                      self.vl_labels,\n",
        "                                      self.vl_arguments, \n",
        "                                      self.vl_keypoints)\n",
        "    self.vl_loss = running_loss/len(self.vl_dataloader)\n",
        "    epoch_preds_map = np.concatenate(epoch_preds_map, axis=0)\n",
        "    self.vl_merged_pred[\"predictions\"] = epoch_preds_map\n",
        "    _, _, self.vl_map_strict, self.vl_map_relaxed= compute_metrics(\"test\",\n",
        "                                                                self.vl_merged_pred,\n",
        "                                                                \"predictions_vl.p.\", \n",
        "                                                                self.vl_labels, \n",
        "                                                                self.vl_arguments, \n",
        "                                                                self.vl_keypoints)\n",
        "    return\n",
        "  \n",
        "  # ------------------------------------- RUNS fine tuning cycle ----------------------------------------------\n",
        "  def fit(self, retrain=False):\n",
        "    \n",
        "    # for each training epoch \n",
        "    for epoch in range(self.epochs):\n",
        "\n",
        "      print(\"Epoch \" + str(epoch+1) + \"/\" + str(self.epochs) + \" started...\")\n",
        "      \n",
        "      # shuffle TR set and create batches \n",
        "      self.tr_merged, self.tr_dataset = shuffle (self.tr_merged, self.tr_dataset)\n",
        "      self.tr_dataloader = DataLoader(self.tr_dataset, batch_size = self.batch_size)\n",
        "\n",
        "      if retrain==False:\n",
        "        # if this is not the final retrain of the model\n",
        "\n",
        "        # shuffle Vl set and create batches \n",
        "        self.vl_merged, self.vl_dataset = shuffle (self.vl_merged, self.vl_dataset)\n",
        "        self.vl_dataloader = DataLoader(self.vl_dataset, batch_size = self.batch_size)\n",
        "\n",
        "        # shuffle VL set with also undecided labels and create batches \n",
        "        self.vl_merged_pred, self.vl_dataset_pred = shuffle (self.vl_merged_pred, self.vl_dataset_pred)\n",
        "        self.vl_dataloader_pred = DataLoader(self.vl_dataset_pred, batch_size = self.batch_size)\n",
        "        \n",
        "        self.training()     # train model on TR set\n",
        "        self.evaluation()   # monitor model behaviour by evaluate them on VL set\n",
        "        # note: we monitor model behaviour on both VL pairs with (0,1) labels as well as on VL pairs on (0,1,undecided) labels\n",
        "\n",
        "        # return training and evaluation history \n",
        "        self.history[\"tr_loss\"].append(self.tr_loss)\n",
        "        self.history[\"tr_cr\"].append(self.tr_cr)\n",
        "        self.history[\"vl_loss\"].append(self.vl_loss)\n",
        "        self.history[\"vl_cr\"].append(self.vl_cr)\n",
        "        self.history[\"vl_map_strict\"].append(self.vl_map_strict)\n",
        "        self.history[\"vl_map_relaxed\"].append(self.vl_map_relaxed)\n",
        "\n",
        "      else:\n",
        "        # if this is the final retrain of the model we don't have a VL set \n",
        "        #just retrain the model on TR+VL set \n",
        "        self.training()\n",
        "        \n",
        "        # return training history \n",
        "        self.history[\"tr_loss\"].append(self.tr_loss)\n",
        "        self.history[\"tr_cr\"].append(self.tr_cr)\n",
        "      print(\"Epoch \" + str(epoch+1) + \"/\" + str(self.epochs) + \" complete!!!\")\n",
        "    \n",
        "    return self.model, self.history\n"
      ],
      "metadata": {
        "id": "ZjTvMiQorBZw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Predictor class**\n",
        "\n",
        "- Use the fully fine-tuned and validated model to get predictions over the test set\n",
        "- Compute evalution metrics on test set \n"
      ],
      "metadata": {
        "id": "yswPXNh15Uul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Predictor():\n",
        "  \n",
        "  def __init__(self, model_name, model_checkpoint, test_data_dict, batch_size):\n",
        "\n",
        "    # load BEST MODEL from the given checkpoint\n",
        "    # here the loaded model has been retrained on both VL e TR set\n",
        "    self.model_name = model_name\n",
        "    self.model  = torch.load(model_checkpoint)\n",
        "    self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    self.model.to(self.device)\n",
        "      \n",
        "    # define TEST DATA (optional)\n",
        "    self.ts_arguments = test_data_dict[\"arguments_df\"]\n",
        "    self.ts_keypoints = test_data_dict[\"keypoints_df\"]\n",
        "    self.ts_labels    = test_data_dict[\"labels_df\"]\n",
        "    self.ts_merged    = test_data_dict[\"preds\"]\n",
        "    self.ts_dataset   = test_data_dict[\"tokenized_preds\"]\n",
        "\n",
        "    self.ts_dataloader = None\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "    self.ts_cr, self.ts_cm, self.ts_map_strict, self.ts_map_relaxed = None, None, None, None\n",
        "    self.history = {\"ts_cr\":[],\"ts_cm\":[], \"ts_map_strict\":[], \"ts_map_relaxed\":[]}\n",
        "  \n",
        "  # -------------------- Get prediction on test set and evaluate model on test set --------------------------------------------------\n",
        "\n",
        "  def predict(self):\n",
        "    \n",
        "    # divide data in batched\n",
        "    self.ts_dataloader = DataLoader(self.ts_dataset, batch_size = self.batch_size)\n",
        "\n",
        "    preds = []\n",
        "    \n",
        "    self.model.eval() # set evaluation mode\n",
        "   \n",
        "    with torch.no_grad(): # no gradient computation is required\n",
        "      \n",
        "      #for each batch\n",
        "      for batch, dl in enumerate(self.ts_dataloader):\n",
        "        \n",
        "        #compute model output (i.e., matching score)\n",
        "        if self.model_name.startswith(\"bert-\")==True:\n",
        "          ids, tti, mask, stance = dl\n",
        "          ids = ids.to(self.device)\n",
        "          tti = tti.to(self.device)\n",
        "          mask = mask.to(self.device)\n",
        "          stance = stance.to(self.device)\n",
        "          output = self.model (ids, mask, stance, tti)\n",
        "\n",
        "        else:\n",
        "          ids, mask, stance = dl\n",
        "          ids = ids.to(self.device)\n",
        "          mask = mask.to(self.device)\n",
        "          stance = stance.to(self.device)\n",
        "          output = self.model (ids, mask, stance)\n",
        "\n",
        "        pred = output.detach().cpu().numpy()\n",
        "        pred = np.hstack(pred)\n",
        "        preds.append(pred)\n",
        "\n",
        "    # save all predictions\n",
        "    preds = np.concatenate(preds, axis=0)\n",
        "    self.ts_merged[\"predictions\"] = preds\n",
        "    # compute metrics to evaluate predictions\n",
        "    self.ts_cr, self.ts_cm, self.ts_map_strict, self.ts_map_relaxed = compute_metrics(\"test\",\n",
        "                                                                                      self.ts_merged,\n",
        "                                                                                      \"predictions_ts.p.\", \n",
        "                                                                                      self.ts_labels, \n",
        "                                                                                      self.ts_arguments, \n",
        "                                                                                      self.ts_keypoints)\n",
        "    # return all required info\n",
        "    self.history[\"ts_cr\"].append(self.ts_cr)\n",
        "    self.history[\"ts_cm\"].append(self.ts_cm)\n",
        "    self.history[\"ts_map_strict\"].append(self.ts_map_strict)\n",
        "    self.history[\"ts_map_relaxed\"].append(self.ts_map_relaxed)\n",
        "\n",
        "    return self.history"
      ],
      "metadata": {
        "id": "4wsRXwdFBObU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Validator class**\n",
        "\n",
        "- Get all possible hyperparameter configiration you want to explore\n",
        "- Run a model selection procedure with hold out validation technique\n",
        "  - Choose the best model based on the validation loss\n",
        "  - Retrain the best model on the full dataset (TR+ VL)\n",
        "  - Store TR e VL peerformance\n",
        "- Run a model assestent procedure with hold out validation technique\n",
        "  - Get predictions on TS set\n",
        "  - Store TS performance"
      ],
      "metadata": {
        "id": "rWvbLzMepoVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "class Validator():\n",
        "  \n",
        "  def __init__(self, tr_data, vl_data, ts_data, hyperparam, model_name):\n",
        "    \n",
        "    self.hyperparams = hyperparam  # dictionary for storing for each  hyperparameter the list of all possible values of the hyperparameter\n",
        "    self.config = {}                # dictionary for storing one possible configuration of hyperparameter values\n",
        "    \n",
        "    # get TR, VL e TS set\n",
        "    self.tr_dict = tr_data\n",
        "    self.vl_dict = vl_data\n",
        "    self.ts_dict = ts_data\n",
        "\n",
        "    # define employed transformer\n",
        "    self.model_name = model_name\n",
        "    self.best_param = None\n",
        "    self.checkpoint = None\n",
        "\n",
        "    self.full_dict = {}\n",
        "\n",
        "\n",
        "  # ---------------------- Get all possible configuration of hyperparameters values --------------------------------------------\n",
        "\n",
        "  def explodeCombination(self):\n",
        "\n",
        "    # transform hyperparam dictionary to a list of all possible combinations of hyperparameter's values\n",
        "    mesh = np.array(np.meshgrid(*self.hyperparams.values()))\n",
        "    self.hyperparams = mesh.T.reshape(-1, len(self.hyperparams))\n",
        "    \n",
        "    return \n",
        "  \n",
        "  # ---------------------- Get all possible configuration of hyperparameters values --------------------------------------------\n",
        "\n",
        "  def get_full_dict(self):\n",
        "\n",
        "    # crate a full dataset by concatenating TR and VL set: use this full dataset for final model retraining\n",
        "\n",
        "    self.full_dict[\"arguments_df\"] = pd.concat([self.tr_dict[\"arguments_df\"],self.vl_dict[\"arguments_df\"]])\n",
        "    self.full_dict[\"keypoints_df\"] = pd.concat([self.tr_dict[\"keypoints_df\"],self.vl_dict[\"keypoints_df\"]])\n",
        "    self.full_dict[\"labels_df\"] = pd.concat([self.tr_dict[\"labels_df\"],self.vl_dict[\"labels_df\"]])\n",
        "    self.full_dict[\"merged_dataset_df\"] = pd.concat([self.tr_dict[\"merged_dataset_df\"], self.vl_dict[\"merged_dataset_df\"]])\n",
        "    self.full_dict[\"tokenized_dataset_tensor\"] = torch.utils.data.ConcatDataset([self.tr_dict[\"tokenized_dataset_tensor\"], self.vl_dict[\"tokenized_dataset_tensor\"]])\n",
        "\n",
        "    return \n",
        "\n",
        "  # ---------------------- MODEL SELECTION: Hold-Out Validation technique ------------------------------------------------------\n",
        "\n",
        "  def modelSelection(self):\n",
        "\n",
        "    self.explodeCombination()\n",
        "    min_loss = float(\"inf\")\n",
        "    # define a list to store loss value of each model that will be trained\n",
        "    all_model_loss = []\n",
        "\n",
        "    i = 0\n",
        "    # try out each one of the possible hyperparameter configuration \n",
        "    for configuration in self.hyperparams:\n",
        "      \n",
        "      # save current hyperparameter configuration and use it to train a model \n",
        "      self.config[\"epochs\"]        = int(configuration[0])\n",
        "      self.config[\"learning_rate\"] = configuration[1]\n",
        "      self.config[\"batch_size\"]    = int(configuration[2])\n",
        "      self.config[\"drop_out\"] = configuration[3]\n",
        "      self.config[\"unit_1\"] = int(configuration[4])\n",
        "\n",
        "      #  create a trainer object and start training the model on TR set\n",
        "      model_trainer = Trainer(model_name = self.model_name, \n",
        "                              model_checkpoint = None,\n",
        "                              train_data_dict = self.tr_dict, \n",
        "                              val_data_dict = self.vl_dict, \n",
        "                              param = self.config)\n",
        "      model, history = model_trainer.fit()\n",
        "      #if history[\"vl_loss\"][-1] <= min_loss:\n",
        "      #torch.save(model, str(self.model_name)+str(self.config)+\"best_model.pt\")\n",
        "      all_model_loss.append(history[\"vl_loss\"][-1])\n",
        "\n",
        "      with open(\"model_selection_result.txt\", \"a\") as file_result:\n",
        "        file_result.write(str(self.config))\n",
        "        file_result.write(json.dumps(history))\n",
        "        file_result.write(\"\\n\")\n",
        "        file_result.close()\n",
        "      \n",
        "      #if i%3 ==0:\n",
        "        #files.download(\"/content/\"+str(self.model_name)+\"model_selection_result.txt\")\n",
        "      #i=i+1\n",
        "    \n",
        "    best_model_loss = min(all_model_loss)\n",
        "    best_loss_idx = [idx for idx, val in enumerate(all_model_loss) if val==best_model_loss]\n",
        "    self.best_param = self.hyperparams[best_loss_idx]\n",
        "\n",
        "    # fine tuning the  best model\n",
        "\n",
        "    self.config[\"epochs\"] = int(self.best_param[0][0])\n",
        "    self.config[\"learning_rate\"] = self.best_param[0][1]\n",
        "    self.config[\"batch_size\"] = int(self.best_param[0][2])\n",
        "    self.config[\"drop_out\"] = self.best_param[0][3]\n",
        "    self.config[\"unit_1\"] = int(self.best_param[0][4])\n",
        "    \n",
        "    #self.checkpoint = str(self.model_name) + str(self.config) + \"best_model.pt\"\n",
        "\n",
        "    return \n",
        "  \n",
        "  # ---------------------- MODEL SELECTION: Hold-Out Validation technique ------------------------------------------------------\n",
        "\n",
        "  def modelAssestment(self):\n",
        "    \n",
        "    # get full dataset and use it\n",
        "    self.get_full_dict()\n",
        "\n",
        "    # retrain model on full dataset \n",
        "    model_trainer = Trainer( model_name = self.model_name, \n",
        "                             model_checkpoint = None,\n",
        "                             train_data_dict = self.full_dict, \n",
        "                             val_data_dict = None,\n",
        "                             param = self.config)\n",
        "    model, history_retrain = model_trainer.fit(retrain = True)\n",
        "    \n",
        "    # save performance obtained on full dataset durinng retrain\n",
        "    with open(\"DEBERTA_retrain_results.txt\", \"a\") as file_result:\n",
        "      file_result.write(str(self.config))\n",
        "      file_result.write(json.dumps(history_retrain))\n",
        "      file_result.close()\n",
        "    \n",
        "    # save the retrained final model in a checkpoint \n",
        "    torch.save(model, \"/content/\"+\"deberta\"+str(self.config)+\"_final_model.pt\")\n",
        "    self.checkpoint = \"deberta\" + str(self.config)+\"_final_model.pt\" \n",
        "\n",
        "    # use predictor class to get predictionn on test set \n",
        "    model_predictor = Predictor(self.model_name, self.checkpoint, self.ts_dict, batch_size = int(self.best_param[0][2]))\n",
        "    history_test = model_predictor.predict()\n",
        "    print(history_test)\n",
        "    \n",
        "    # save info about model performance on test set \n",
        "    with open(\"DEBERTA_test_results.txt\", \"a\") as file_result:\n",
        "      file_result.write(str(self.config))\n",
        "      file_result.write(str(history_test))\n",
        "      file_result.close()\n",
        "    \n",
        "    \n",
        "    #files.download(\"/content/DEBERTA_retrain_results.txt\")\n",
        "    #files.download(\"/content/DEBERTA_test_results.txt\")\n",
        "    \n",
        "    return \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DObVD3Ln2fFe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Main**\n"
      ],
      "metadata": {
        "id": "E4-Ccon-p3Qj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- Choose the Hugging face tokenizer and model you want to use for the task -----------------------------\n",
        "\n",
        "# possible options: \"bert-base-uncased\", \"roberta-base\", \"albert-base-v2\"\n",
        "used_tokenizer = \"microsoft/deberta-base\"\n",
        "used_model     = \"microsoft/deberta-base\"\n",
        "\n",
        "# -------------------- Prepare all dataset needed to solve the task: use DatasetParser class ---------------------------------\n",
        "\n",
        "dataset_directory = \"/content/KPA_2021_shared_task/kpm_data\"  # directory for dataset used for training, finetuning and development\n",
        "testset_directory = \"/content/KPA_2021_shared_task/test_data\" # directory for dataset used for testing\n",
        "\n",
        "dataset_parser = DatasetParser(tokenizer_name = used_tokenizer)\n",
        "tr_data_dict = dataset_parser.get_data(data_directory = dataset_directory, mode = \"train\")\n",
        "vl_data_dict = dataset_parser.get_data(data_directory = dataset_directory, mode = \"dev\")\n",
        "ts_data_dict = dataset_parser.get_data(data_directory = testset_directory, mode=\"test\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509,
          "referenced_widgets": [
            "eb539cd48e724460adc74fa8609cc7d4",
            "d4f7a4253987449ba9072925ef4dae66",
            "148a1ad99fb74b92827deffce600b2e4",
            "8cff21ac2f7a486186d552443fd6edf1",
            "ba67ddb9dd1a4a4b94371fbe26e033bd",
            "3fbc91e74b934b7686aa41013afb96f6",
            "7095fd34ae4841988128e9ebb95873d6",
            "f3af64b82f5647528368efdf2112f089",
            "61315eabf44c4c8eb07c850f2d882266",
            "963d18c57f334739ba06e5f3ef10e961",
            "90dabb31e217413a9adcdaf5afefd166",
            "44844bcce4ce4a9a8aade9e177e90d47",
            "267f4770580e4b04877d6c635a49f0da",
            "6cd08914df334d41a683f509e82e1929",
            "69741605fc4d4bf9aa8239286ca820d5",
            "a2cfdb3dc49d4ca7938d86a85505d5d7",
            "d24d80677dc74ad0a54e03ff33593692",
            "72b649a03d7543b180ee511e2af83ab7",
            "dac29984102342088bde21feb68865a2",
            "b1b7a74d2f084aeab2651199426f4ca2",
            "24a76699b4264b899540156622b588c4",
            "7efb3fe9f5904ecc8f8a6b2f7bc0bf4f",
            "b3cec38c2e5b4ef9852d209f0f2f68b9",
            "92ef805cc3b5491694134b69b1be00ea",
            "72035406480f40919a8e457813dd257f",
            "aafcd91992ae49db8e89c0e84e7c836a",
            "aa19ac20892144cd90c87475096e5054",
            "a330db464a4844d8a1dedf4a19a71bcc",
            "eb0d1186ce9c4306a8b9bbfba486438b",
            "faa11f9ebe134d44937ecd353ce8e4e2",
            "5d1913d29b254b59815e9883e973672d",
            "cb35c7f8de9e4a5e94eed3f54c271e63",
            "e9b55786c09f4687a14914c6b2f0f5ca",
            "3dccd6a39438418392dd4ac4a5d6e961",
            "545805aab9be4e9d8e795d467aa99846",
            "d2a6c8c5323043b2912daa2ac44fb324",
            "d15091f26e0140a385ea4b2ad3b74cd3",
            "bd9980a9e0f84ca3b2729432b6d71c29",
            "7f9e956e7cec4c6cb76d92b2615a2caa",
            "534037877e88475eb079713da35abac9",
            "2d6af7d6855241b5a66c1bdd7d0bc044",
            "242f0dd48a424b2e8e75999a2f32b9d4",
            "68a516ff50194f0bbe50f397107c781c",
            "d4c409c3314e4bc8b90df00665ff2676"
          ]
        },
        "id": "pytmIuaKjUJe",
        "outputId": "99617a1d-cb40-4ad2-f783-55c9da22f782"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb539cd48e724460adc74fa8609cc7d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/474 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44844bcce4ce4a9a8aade9e177e90d47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading vocab.json:   0%|          | 0.00/878k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3cec38c2e5b4ef9852d209f0f2f68b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3dccd6a39438418392dd4ac4a5d6e961"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data has been loaded\n",
            "train data has been preprocessed\n",
            "train dataset has been created\n",
            "train dataset has been tokenized and transformed to tensors\n",
            "train predictions file has been created\n",
            "train tokenized predictions file has been created\n",
            "\n",
            "dev data has been loaded\n",
            "dev data has been preprocessed\n",
            "dev dataset has been created\n",
            "dev dataset has been tokenized and transformed to tensors\n",
            "dev predictions file has been created\n",
            "dev tokenized predictions file has been created\n",
            "\n",
            "test data has been loaded\n",
            "test data has been preprocessed\n",
            "test dataset has been created\n",
            "test dataset has been tokenized and transformed to tensors\n",
            "test predictions file has been created\n",
            "test tokenized predictions file has been created\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define hyperparameter value you want to use ... \n",
        "# (also more values for each hyperparameter if your exploring hypeparameters space)\n",
        "hyperparameter_value = {\"epoch\":[2], \n",
        "                        \"lr\":[1e-05],\n",
        "                        \"batch_size\":[32], \n",
        "                        \"drop_out\":[0.2], \n",
        "                        \"unit_1\":[10]}\n",
        "\n",
        "# -------------------- Run a validation process --------------------------------------------------\n",
        "\n",
        "validator = Validator(tr_data = tr_data_dict,\n",
        "                      vl_data = vl_data_dict,\n",
        "                      ts_data = ts_data_dict, \n",
        "                      hyperparam = hyperparameter_value, \n",
        "                      model_name = used_model)\n",
        "\n",
        "validator.modelSelection()    # runs model selection\n",
        "validator.modelAssestment()   # runs model assestments\n"
      ],
      "metadata": {
        "id": "WTd7VNvaqe5m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450,
          "referenced_widgets": [
            "e7157dfe07724d75bebd7cb8a0d2ec51",
            "3dbb4229b44b40b0a97f6af6577a496e",
            "c4bb2c9150f24803be479774273adf2a",
            "26c21835763b41d18760cd41620b56c1",
            "0148b881295042259aa25bdc920d28c8",
            "4b7e0c7618a64dd189209c7e5a414f19",
            "8fc94f8eb9e44d939974d1d7be01bca6",
            "8f208568480446f7bb20361771935a7b",
            "55ad7b2237ce41d5857e984a57fad74d",
            "dbddc1bcb8514416bda10aebb0acc07f",
            "3fa0abc05cbe49dda357146118d2e278"
          ]
        },
        "outputId": "9acb9562-07f2-463a-a404-260a999af382"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/533M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7157dfe07724d75bebd7cb8a0d2ec51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n",
            "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2 started...\n",
            "Training started!!\n",
            "Evaluating...\n",
            "Epoch 1/2 complete!!!\n",
            "Epoch 2/2 started...\n",
            "Training started!!\n",
            "Evaluating...\n",
            "Epoch 2/2 complete!!!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n",
            "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2 started...\n",
            "Training started!!\n",
            "Epoch 1/2 complete!!!\n",
            "Epoch 2/2 started...\n",
            "Training started!!\n",
            "Epoch 2/2 complete!!!\n",
            "{'ts_cr': ['              precision    recall  f1-score   support\\n\\n           0       0.83      0.62      0.71       170\\n           1       0.86      0.95      0.90       422\\n\\n    accuracy                           0.85       592\\n   macro avg       0.84      0.78      0.80       592\\nweighted avg       0.85      0.85      0.85       592\\n'], 'ts_cm': [array([[105,  65],\n",
            "       [ 22, 400]])], 'ts_map_strict': [0.7347296941803435], 'ts_map_relaxed': [0.8929432314475476]}\n"
          ]
        }
      ]
    }
  ]
}